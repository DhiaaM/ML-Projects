# -*- coding: utf-8 -*-
"""Simple Linear Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10OOr0m2vBIIIgXkceUyPbPUTX3DcNEKT

# SALARY PREDICTION
"""

import os
import numpy as np  
import pandas as pd  
import matplotlib.pyplot as plt  
import seaborn as sns  
from sklearn import linear_model 
import statsmodels.formula.api as smf

"""## PART 1: Data Handling

 
"""

#Now I use pandas to load the data and convert the csv into a dataframe
data = pd.read_csv('/content/Salary_Data.csv') 
#Using the head method to see the head of the dataframe
data.head()

# DATA Available from: https://www.kaggle.com/karthickveerakumar/salary-data-simple-linear-regression

#Describe method will provide an overview of the data
data.describe()

# Analyze how closely the variables are related. The closer its value is to 1, the more variability the model explains.
data.corr()

# Using seaborn to make a heat graph  
sns.heatmap(data.corr())

# The first parameter calls the data, then the x and y  
sns.scatterplot(data=data, x="YearsExperience",y="Salary")

"""## PART 2: Data Analysis

### Linear Regression using Sklearn
"""

# Conducting Linear Regression method and inserting data using the fit method
# Additional bracket to transform it into 2D
lm = linear_model.LinearRegression(). fit(data[["YearsExperience"]],data[["Salary"]])
# Using the predict method
result=lm.predict (data[["YearsExperience"]])

# Creating a new column to place contents of the result variable
data["Prediction-Sklearn"]= result
data.head()

# Create a new column to show the error salary minus prediction (expected values)
data["Prediction Error-Sklearn"] = data["Salary"]-data["Prediction-Sklearn"]
data.head()

# Plotting Linear Regression graph with Sklearn  
plt.scatter(data["YearsExperience"], data["Salary"])
plt.plot(data["YearsExperience"],data["Prediction-Sklearn"], color="green")
plt.ylabel("Salary")
plt.xlabel("Years of Experience")
plt.title("Linear Regression: Years of Experience & Corresponging Salary ")

lm.coef_

lm.intercept_

#y = wo + w1*x
#Salary = 25792.20019867 + 9449.96232146 * YearsExperience

#Testing for 9 years of experience
Salary = 25792.20019867 + 9449.96232146 * 9 
Salary

lm.predict([[9]]) #colchetes pois exige-se 2D

"""### Linear Regression using Statsmodels"""

# OLS (ordinary list squares) is a method for linear regression (it is also the method used by Sklearn, although not explicitly)
#lm_version2 = smf.ols(formula = " Y ~ X") -> the variable Y is a function of x (Y is the dependent variable)
lm_version2 = smf.ols(formula = " Salary ~ YearsExperience",data=data).fit() #fit method will adjust the model according to the data
lm_version2.predict() #To find the prediction. There is no need to put x as a parameter because the method does it automatically 
# Storing the prediction in a variable:
result2=lm_version2.predict()

#Checking the table:
data.head()

# Creating a new column:
data["Prediction-Statsmodels"]=result2
data.head()

# Creating the last column
data["Prediction Error-Statsmodels"] = data["Salary"] - data["Prediction-Statsmodels"]
data.head()

# Summary - from Statsmodels 
lm_version2.summary()

# Plotting Linear Regression graph with Statsmodels 
plt.scatter(data["YearsExperience"], data["Salary"])
plt.plot(data["YearsExperience"],data["Prediction-Statsmodels"], color="green")
plt.ylabel("Salary")
plt.xlabel("Years of Experience")
plt.title("Linear Regression: Years of Experience & Corresponging Salary ")

"""#### Linear Regression with regplot"""

# Using seaborn and regplot to draw a line giving the margin of error
sns.regplot(x=data["YearsExperience"],y=data["Salary"])

